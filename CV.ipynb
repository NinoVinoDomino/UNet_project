{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f7166e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Занятие 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da9159",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 1\n",
    "\n",
    "Расставьте соответствие между названиями задач и их формальной постановкой:\n",
    " \n",
    "**Правильный ответ:**\n",
    "\n",
    "Детекция объектов это обвести объекты на изображении ограничивающими прямоугольниками и классифицировать.\n",
    "\n",
    "Семантическая сегментация это классифицировать каждый пиксель изображения.\n",
    "\n",
    "Сегментация объектов это классифицировать каждый пиксель изображения и разделить объекты одного класса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7a85e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 2\n",
    "\n",
    "Посчитайте меру Жаккара для класса 0, для класса 1 и для класса 2. Посчитайте среднее, округлите до 4 знаков после запятой.\n",
    "\n",
    "Две картинки...\n",
    "\n",
    "**Правильный ответ:**\n",
    "\n",
    "Мера Жаккара:\n",
    "\n",
    "$$J_k(y, a) = \\dfrac{\\sum\\limits_{i=1}^{n}[y_i = k][a_i = k]}{\\sum\\limits_{i=1}^{n}\\max([y_i = k], [a_i = k])}$$\n",
    "\n",
    "То есть нам нужно для классов 0, 1 и 2 посчитать количество пикселей, у которых совпадает ответ модели с правильным ответом, а также посчитать сколько всего пикселей содержит этот класс, хотя бы от прогноза модели или правильного ответа. Ну или посчитать пересечение масок вида `[img == C]` и объединение масок `[img == C]`.\n",
    "\n",
    "Для класса 0: пересечение 0, объединение 12\n",
    "Для класса 1: пересечение 5, объединение 13\n",
    "Для класса 2: пересечение 4, объединение 16\n",
    "\n",
    "Итого: (5/13 + 4/16) / 3 = 0.2115 с округлением до 4 знаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ddaef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 3\n",
    "\n",
    "Чем идейно плоха архитектура Fully Convolutional Network для задачи сегментации? Выберите все подходящие варианты:\n",
    "\n",
    " 1. Слишком много параметров, легко переобучается\n",
    " 2. Используется макс-пулинг, теряем информацию про то, где объект расположен\n",
    " 3. Тензор с последнего слоя слишком маленький\n",
    " 4. Используется устаревшая архитектура AlexNet\n",
    "\n",
    "**Правильный ответ:** все кроме первого верно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f1e5b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 4\n",
    "\n",
    "Усложните модель `UNET` с семинара, обучите ее на датасете OXFORD-PETS, добейтесь попиксельной Accuracy в 88%. Для этого вам понадобится добавить в нее еще блоков вниз и блоков вверх, а также возможно увеличить `base_channels`.\n",
    "\n",
    "Используйте следующий трансформ для изображений:\n",
    "\n",
    "```\n",
    "transform = T.Compose(\n",
    "    [\n",
    "        T.Resize((256, 256)),\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "Сдайте свои предсказания для тестовой выборки этого датасета (`split='test'`). Сделайте предсказания для следующих объектов:\n",
    "\n",
    "```\n",
    "np.random.seed(100)\n",
    "idx = np.random.randint(len(valid_dataset), size=200)\n",
    "```\n",
    "\n",
    "Загрузите свои предсказания в чекер, воспользуйтесь функциями `torch.save`, ваш тензор с предсказаниями должен иметь размер `[200, 1, 256, 256]`.\n",
    "\n",
    "**Правильный ответ:**\n",
    "\n",
    "Сделаем все как в задании:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519219d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv_plus_conv(in_channels: int, out_channels: int):\n",
    "    \"\"\"\n",
    "    Makes UNet block\n",
    "    :param in_channels: input channels\n",
    "    :param out_channels: output channels\n",
    "    :return: UNet block\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.BatchNorm2d(num_features=out_channels),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.BatchNorm2d(num_features=out_channels),\n",
    "        nn.LeakyReLU(0.2),\n",
    "    )\n",
    "\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        base_channels = 32\n",
    "\n",
    "        self.down1 = conv_plus_conv(3, base_channels)\n",
    "        self.down2 = conv_plus_conv(base_channels, base_channels * 2)\n",
    "        self.down3 = conv_plus_conv(base_channels * 2, base_channels * 4)\n",
    "        self.down4 = conv_plus_conv(base_channels * 4, base_channels * 8)\n",
    "        self.down5 = conv_plus_conv(base_channels * 8, base_channels * 16)\n",
    "\n",
    "        self.up1 = conv_plus_conv(base_channels * 2, base_channels)\n",
    "        self.up2 = conv_plus_conv(base_channels * 4, base_channels)\n",
    "        self.up3 = conv_plus_conv(base_channels * 8, base_channels * 2)\n",
    "        self.up4 = conv_plus_conv(base_channels * 16, base_channels * 4)\n",
    "        self.up5 = conv_plus_conv(base_channels * 32, base_channels * 8)\n",
    "\n",
    "        self.bottleneck = conv_plus_conv(base_channels * 16, base_channels * 16)\n",
    "\n",
    "        self.out = nn.Conv2d(in_channels=base_channels, out_channels=3, kernel_size=1)\n",
    "\n",
    "        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (N, N, 3)\n",
    "\n",
    "        residual1 = self.down1(x)  # x.shape: (N, N, 3) -> (N, N, base_channels)\n",
    "        x = self.downsample(residual1)  # x.shape: (N, N, base_channels) -> (N // 2, N // 2, base_channels)\n",
    "\n",
    "        residual2 = self.down2(x)  # x.shape: (N // 2, N // 2, base_channels) -> (N // 2, N // 2, base_channels * 2)\n",
    "        x = self.downsample(residual2)  # x.shape: (N // 2, N // 2, base_channels * 2) -> (N // 4, N // 4, base_channels * 2)\n",
    "\n",
    "        residual3 = self.down3(x)\n",
    "        x = self.downsample(residual3)\n",
    "\n",
    "        residual4 = self.down4(x)\n",
    "        x = self.downsample(residual4)\n",
    "\n",
    "        residual5 = self.down5(x)\n",
    "        x = self.downsample(residual5)\n",
    "\n",
    "        # LATENT SPACE DIMENSION DIM = N // 4\n",
    "        # SOME MANIPULATION MAYBE\n",
    "        x = self.bottleneck(x)  # x.shape: (N // 4, N // 4, base_channels * 2) -> (N // 4, N // 4, base_channels * 2)\n",
    "        # SOME MANIPULATION MAYBE\n",
    "        # LATENT SPACE DIMENSION DIM = N // 4\n",
    "\n",
    "        x = nn.functional.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat((x, residual5), dim=1)\n",
    "        x = self.up5(x)\n",
    "\n",
    "        x = nn.functional.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat((x, residual4), dim=1)\n",
    "        x = self.up4(x)\n",
    "\n",
    "        x = nn.functional.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat((x, residual3), dim=1)\n",
    "        x = self.up3(x)\n",
    "\n",
    "        x = nn.functional.interpolate(x, scale_factor=2)  # x.shape: (N // 4, N // 4, base_channels * 2) -> (N // 2, N // 2, base_channels * 2)\n",
    "        x = torch.cat((x, residual2), dim=1)  # x.shape: (N // 2, N // 2, base_channels * 2) -> (N // 2, N // 2, base_channels * 4)\n",
    "        x = self.up2(x)  # x.shape: (N // 2, N // 2, base_channels * 4) -> (N // 2, N // 2, base_channels)\n",
    "\n",
    "        x = nn.functional.interpolate(x, scale_factor=2)  # x.shape: (N // 2, N // 2, base_channels) -> (N, N, base_channels)\n",
    "        x = torch.cat((x, residual1), dim=1)  # x.shape: (N, N, base_channels) -> (N, N, base_channels * 2)\n",
    "        x = self.up1(x)  # x.shape: (N, N, base_channels * 2) -> (N, N, base_channels)\n",
    "\n",
    "        x = self.out(x)  # x.shape: (N, N, base_channels) -> (N, N, 3)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3510d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from IPython.display import clear_output\n",
    "from torch.optim import Adam\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    loss_fn,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in tqdm(data_loader, desc='Train'):\n",
    "        bs = y.size(0)\n",
    "\n",
    "        x, y = x.to(device), y.squeeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        _, y_pred = output.max(dim=1)\n",
    "        total += y.size(0) * y.size(1) * y.size(2)\n",
    "        correct += (y == y_pred).sum().item()\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "    model: nn.Module, data_loader: DataLoader, loss_fn, device: torch.device\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in tqdm(data_loader, desc='Evaluation'):\n",
    "        bs = y.size(0)\n",
    "\n",
    "        x, y = x.to(device), y.squeeze(1).to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, y_pred = output.max(dim=1)\n",
    "        total += y.size(0) * y.size(1) * y.size(2)\n",
    "        correct += (y == y_pred).sum().item()\n",
    "\n",
    "    total_loss /= len(data_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return total_loss, accuracy\n",
    "\n",
    "\n",
    "def plot_stats(\n",
    "    train_loss: list[float],\n",
    "    valid_loss: list[float],\n",
    "    train_accuracy: list[float],\n",
    "    valid_accuracy: list[float],\n",
    "    title: str\n",
    "):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' loss')\n",
    "\n",
    "    plt.plot(train_loss, label='Train loss')\n",
    "    plt.plot(valid_loss, label='Valid loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' accuracy')\n",
    "    \n",
    "    plt.plot(train_accuracy, label='Train accuracy')\n",
    "    plt.plot(valid_accuracy, label='Valid accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def whole_train_valid_cycle(\n",
    "    model, train_loader, valid_loader, optimizer, loss_fn, device, threshold, title\n",
    "):\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "    train_accuracy_history, valid_accuracy_history = [], []\n",
    "\n",
    "    for epoch in range(100):\n",
    "        train_loss, train_accuracy = train(\n",
    "            model, train_loader, optimizer, loss_fn, device\n",
    "        )\n",
    "        valid_loss, valid_accuracy = evaluate(model, valid_loader, loss_fn, device)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        valid_accuracy_history.append(valid_accuracy)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        plot_stats(\n",
    "            train_loss_history,\n",
    "            valid_loss_history,\n",
    "            train_accuracy_history,\n",
    "            valid_accuracy_history,\n",
    "            title,\n",
    "        )\n",
    "\n",
    "        if valid_accuracy >= threshold:\n",
    "            break\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict_segmentation(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    for x, _ in loader:\n",
    "        output = model(x.to(device)).cpu()\n",
    "\n",
    "        prediction.append(torch.argmax(output, dim=1))\n",
    "\n",
    "    prediction = torch.cat(prediction)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def main(model_class, threshold, title):\n",
    "    set_seed(0xDEADF00D)\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.Resize((256, 256)),\n",
    "            T.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    target_transform = T.Compose(\n",
    "        [\n",
    "            T.Resize((256, 256)),\n",
    "            T.PILToTensor(),\n",
    "            T.Lambda(lambda x: (x - 1).long())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset = OxfordIIITPet('/home/jupyter/mnt/datasets/pets', transform=transform, download=True, target_transform=target_transform, target_types='segmentation')\n",
    "    valid_dataset = OxfordIIITPet('/home/jupyter/mnt/datasets/pets', transform=transform, download=True, split='test', target_transform=target_transform, target_types='segmentation')\n",
    "    \n",
    "    np.random.seed(100)\n",
    "    idx = np.random.randint(len(valid_dataset), size=200).tolist()\n",
    "    \n",
    "    valid_dataset = Subset(valid_dataset, idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model_class().to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    whole_train_valid_cycle(\n",
    "        model, train_loader, valid_loader, optimizer, loss_fn, device, threshold, title\n",
    "    )\n",
    "\n",
    "    torch.save(predict_segmentation(model, valid_loader, device).reshape([200, 1, 256, 256]).to(torch.uint8), 'prediction.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fce16a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "main(UNET, 0.88, 'UNET segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 5\n",
    "\n",
    "Расставьте соответствие:\n",
    "\n",
    " 1. One-shot detection -> Подходы к решению задачи детекции объектов, когда прямоугольники выделяются и классифицируются одной моделью\n",
    " 2. MAP -> Метрика для измерения качества детекции\n",
    " 3. Two-shot detection -> Подходы к решению задачи детекции объектов, когда прямоугольники сначала как-то выделяются, а потом классифицируются\n",
    " 4. Non-maximum supression -> Метод для прореживания прямоугольников, выданных моделью"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 6\n",
    "\n",
    "Расположите этапы работы архитектуры R-CNN в порядке их применения:\n",
    "\n",
    "1. Выделить области-кандидаты из изображения\n",
    "2. Посчитать признаки с помощью сверточной сети\n",
    "3. Классификация с помощью SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}